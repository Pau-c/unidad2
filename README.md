# PresentaciÃ³n
<img width="1024" height="520" alt="Copia de Cheers!" src="https://github.com/user-attachments/assets/bc04834d-28b5-401d-a99a-4737208591eb" />



---

## Integrantes

| Nombre                        | Correo ElectrÃ³nico             | Usuario Github |
|-------------------------------|--------------------------------|----------------|
| Ariel Omar Leche              | ariel.leche@gmail.com          | ARielleche     |
| Diego Ariel Gutierrez         | dgutierrez.m79@gmail.com       | Diego-wert89   |
| JosÃ© Alberto Rubio            | rubiojosealberto@gmail.com     | rubiojar       |
| Maria Paula Coba              | mpcobas@gmail.com              | Pau-c          |
| Mauro Ruben De Natale         | maurodenatale@gmail.com        | M3T30R0-dev    |



> [!TIP]
> [Live Demo](https://deepnote.com/workspace/test-a96860ea-b228-4e9e-a13d-9edd20f60d93/project/MP-Cs-Untitled-project-a2cd30de-aa34-492f-bd7f-baf47d78ec21/notebook/ej3u2-47c02c388b264ca69ce0f37ecfdb9215?utm_content=a2cd30de-aa34-492f-bd7f-baf47d78ec21)

## DescripciÃ³n

En este proyecto de python se analizan las tendencias musicales en streaming medida por Billboard desde el aÃ±o 2013 hasta 2025.
Se  guarda el dataset en Supabase, se lo recupera en un dataframe y se lo trabaja en un notebook de Jupyter para su exploraciÃ³n y visualizaciÃ³n.

## Instrucciones 
### - Bajar dataset, nos vamos a centrar en el archivo `streaming_songs.csv`
>[Dataset original](https://www.kaggle.com/datasets/ludmin/billboard?resource=download)

## PROCESO ETL 

      ##Proceso exploratorio

            Nombre de archivo CVS descargado= streaming_songs.csv
            Cantidad de columnas: 8
            Date,Song,Artist,Rank,Last Week,Peak Position,Weeks in Charts,Image URL
            Cantidad de registros:33050
            Diccionario de dataset (funciÃ³n de cada columna y tipo de dato) 
            Limpieza ( se borra Ãºltima columna  â€œ image URLâ€ )   
            Cantidad de registros (null o faltantes) por columna  
                    Date(100% ok),Song,Artist(100% ok),Rank(100% ok),Last Week(100% ok),Peak Position(100% ok),Weeks in Charts(100% ok)

``` 
      
      # DICCIONARIO DE DATOS DEL DATASET
            
                    1-Date: Tipo: Fecha (formato yyyy/mm/dd) DescripciÃ³n: Fecha en la que se registrÃ³ el ranking de la canciÃ³n.
                    2-Song: Tipo: Texto (string) DescripciÃ³n: Nombre de la canciÃ³n en el ranking.
                    3-Artist: Tipo: Texto (string) DescripciÃ³n: Nombre del artista o grupo musical (puede incluir â€œFeaturingâ€ sÃ­ hay colaboraciones).
                    4-Rank: Tipo: NumÃ©rico entero DescripciÃ³n: PosiciÃ³n actual de la canciÃ³n en el ranking (1 = primer lugar).
                    5-Last_Week:Tipo: NumÃ©rico entero  DescripciÃ³n: PosiciÃ³n que ocupaba la canciÃ³n en la semana anterior.
                    6-Peak_Position:Tipo: NumÃ©rico entero  DescripciÃ³n: Mejor posiciÃ³n alcanzada por la canciÃ³n en el ranking hasta la fecha.
                    7-Weeks_in_Charts:Tipo: NumÃ©rico entero DescripciÃ³n: NÃºmero de semanas que la canciÃ³n lleva en el ranking.

              
```	
      ##   Proceso de TransformaciÃ³n 
		    Nota: usar cualquier herramienta de ediciÃ³n o cÃ³digo.
		    Limpieza ( se borra Ãºltima columna  â€œ image URLâ€)
		    Editar CSV  creando  columna ID (tabulaciÃ³n â€œId,â€)
			                        ID,Date,Song,Artist,Rank,Last Week,Peak_Position,Weeks_in_Charts
		    Editar campos null o con â€œ-â€ (guiÃ²n) con nÃºmero 0
		    Nombre de columnas colocar â€œ_â€ en sus nombres de las columnas
                                    ID,Date,Song,Artist,Rank,Last Week,Peak_Position,Weeks_in_Charts
            Generar nuevo archivo .CSV con nombre= dataset_artistas_CSV_PARA_BD.csv

     
---
## Base de datos en Supabase 
- crear nuevo proyecto: elegir region y password (generar password, copiarlo y guardarlo)
- Ir a la barra de la izq, table editor, crear nueva tabla, elegir nombre: `Dataset_Ranking`, click en boton importar data de .CSV -> elegir archivo `dataset_artistas_CSV` y guardar.
- En barra lateral ir a `project settings` -> api keys y copiar la de anon public
- En barra lateral ir a `data api`: copiar direccion de project url para usar en los siguientes pasos.
- Para que se tenga acceso a la tabla en la barra lateral ir a authentication -> policies y `Enable read access for all users`
  Nota: se encuentra scrip de creacion de tabla e insert de los 33050 registros en repositorio=> unidad2\archivos\Creacion_e_insert_Dataset_Ranking_full.sql , podria usar la consola de supabase de 1000 regristros para insert manualmente.
---
``` 
## âš™ï¸ Estructura del Repositorio

UNIDAD2/
â”œâ”€â”€ .github/
â”œâ”€â”€ .ipynb_checkpoints/
â”‚   â””â”€â”€ ej3u2-checkpoint.ipynb
â”œâ”€â”€ .venv/
â”‚   â”œâ”€â”€ etc/
â”‚   â”œâ”€â”€ Lib/
â”‚   â”œâ”€â”€ Scripts/
â”‚   â””â”€â”€ share/
â”œâ”€â”€ .lock
â”œâ”€â”€ pyvenv.cfg
â”œâ”€â”€ archivos/
â”‚   â”œâ”€â”€ Creacion_e_insert_Dataset_Ranking_full.sql
â”‚   â”œâ”€â”€ dataset_artistas_CSV.csv
â”‚   â””â”€â”€ streaming_songs_original.csv
â”œâ”€â”€ unidad2/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ ej3u2.ipynb
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ uv.lock


``` 
## ğŸ› ï¸ Requisitos e InstalaciÃ³n

<!-- PROJECT SHIELDS -->
[![deepnoteBadge][deepnote-shield]][deepnote-url]
[![pythonBadge][python-shield]][python-url]
[![pandasBadge][pandas-shield]][pandas-url]
[![plotlyBadge][plotly-shield]][plotly-url]
[![uvBadge][uv-shield]][uv-url]
[![supabaseBadge][supabase-shield]][supabase-url]
[![jupyterBadge][jupyter-shield]][jupyter-url]
[![dotenvBadge][dotenv-shield]][dotenv-url]
<!-- PROJECT SHIELDS -->

***************************************************************************************************************
PASOS PARA USAR IDE con UV y COMENZAR DESA
****************************************************************************************************************

### - Instalar uv en la pc si es necesario (en terminal de Windows):

   Abrir un pront CMD en win  o temrinal ID, ver el pront con PS:>    y ejecutar
```
 powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### - Clonar repo:
```
git clone https://github.com/Pau-c/unidad2.git
```


### - Abrir proyecto en un IDE
### - Crear un archivo en la raÃ­z del proyecto llamado .env
- Dentro pegar la url y la key de supabase que se copiaron antes siguiendo este formato (sin espacios ni comillas):
>SUPABASE_URL=https://nbctuthbio.supabase.co

>SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6I

### - Crear entorno virtual:
Si todavÃ­a no se instalÃ³ uv en el sistema como en el primer paso, en terminal: `pip install uv` y luego  ejecutar:
```
uv venv
```

### - Sincronizar entorno virtual al instalar el proyecto y luego de cada cambio en el .toml
```
uv sync
```

### -Elegir kernel
>Para que el cÃ³digo del notebook funcione,  indicarle a VS Code que utilice el Python >que estÃ¡ dentro del nuevo entorno. Esto se hace dentro de la interfaz del notebook:

> [!IMPORTANT]
> Abrir el archivo `.ipynb` en VS Code.
> 1. Hacer clic en el selector del kernel (la esquina superior derecha).
> 2. Seleccionar otro kernel.
> 3. Elegir el kernel que tenga el nombre del proyecto.


#### asegurarse estar en el etorno correcto y activado: De ser necesario correr en terminal: `.venv\Scripts\activate`

## correr archivo en terminal con:

```
 uv run --env-file .env jupyter lab
```

> - Una vez abierto el notebook .ipynb en el browser, en la esquina superior derecha Hacer clic en `ipkernel` y elegir `start python kernel -Python 3`. de ser necesario ir al menÃº: run -> `restart kernel and run all cells`


<!-- PROJECT SHIELDS VARIABLES-->
[deepnote-shield]:https://img.shields.io/badge/Live-Deepnote-black?style=flat&labelColor=%23808080k&color=de6d40&logo=deepnote&logoColor=white
[deepnote-url]: https://deepnote.com/
[dotenv-shield]:https://img.shields.io/badge/env-dotenv-black?style=flat&labelColor=%23808080k&color=fec260&logo=dotenv&logoColor=white
[dotenv-url]:https://pypi.org/project/python-dotenv/
[pandas-shield]:https://img.shields.io/badge/Data_analysis-Pandas-black?style=flat&labelColor=%23808080k&color=453076&logo=pandas
[pandas-url]:https://pandas.pydata.org/
[python-shield]:https://img.shields.io/badge/Language-Python-black?style=flat&labelColor=%23808080k&color=2a0944&logo=python&logoColor=white
[python-url]: https://www.python.org/
[plotly-shield]:https://img.shields.io/badge/Data_Viz-Plotly-black?style=flat&labelColor=%23808080k&color=9ABF80&logo=plotly&logoColor=white
[plotly-url]: https://plotly.com/python/
[uv-shield]:https://img.shields.io/badge/Dependencias-UV-black?style=flat&labelColor=%23808080k&color=2a0944&logo=uv&logoColor=white
[uv-url]: https://github.com/astral-sh/uv
[supabase-shield]:https://img.shields.io/badge/DB-supabase-black?style=flat&labelColor=%23808080k&color=166866&logo=supabase&logoColor=white
[supabase-url]: https://supabase.com/
[jupyter-shield]:https://img.shields.io/badge/Notebook-jupyter-black?style=flat&labelColor=%23808080k&color=fec260&logo=Jupyter&logoColor=white
[jupyter-url]: https://jupyter.org/


flowchart TD

    %% FUENTE DE DATOS
    A[ğŸ“‚ Fuente de Datos\nstreaming_songs.csv (Kaggle)] --> B[âš™ï¸ Proceso ETL]

    %% ETL
    subgraph ETL[Proceso ETL]
        B1[Limpieza de datos\n(eliminar columnas, normalizar nombres)]
        B2[CreaciÃ³n de ID Ãºnico]
        B3[Manejo de nulos\n(-, null â†’ 0)]
        B4[Salida:\ndataset_artistas_CSV_PARA_BD.csv]
        B1 --> B2 --> B3 --> B4
    end

    B4 --> C[ğŸ—„ï¸ Supabase\n(Carga de tabla Dataset_Ranking)]

    %% ENTORNO DEV
    subgraph DEV[ConfiguraciÃ³n del Entorno de Desarrollo]
        D1[Clonar repositorio]
        D2[Configurar credenciales\n(.env)]
        D3[Crear venv con uv venv\n+ uv sync]
    end
    C --> DEV

    %% NOTEBOOK
    subgraph Jupyter[AnÃ¡lisis y ExploraciÃ³n]
        E1[ej3u2.ipynb]
        E2[ConexiÃ³n a Supabase\nusando .env]
        E3[DataFrame Pandas]
        E4[ExploraciÃ³n, anÃ¡lisis y\nvisualizaciÃ³n con Plotly]
        E1 --> E2 --> E3 --> E4
    end
    DEV --> Jupyter

    %% VISUALIZACIÃ“N FINAL
    subgraph VIS[VisualizaciÃ³n y ProducciÃ³n]
        F1[Pruebas Locales:\nuv run jupyter lab]
        F2[Demo en Nube:\nDeepnote.com]
    end
    Jupyter --> VIS
